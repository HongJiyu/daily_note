# basic concepts

## near realtime

近乎实时：从录入文档到文档变得可查，通常只需要间隔1s。

## cluster

集群是多个节点（es服务）的集合。每个集群都有自己的集群名，默认为elasticsearch。集群只有一个节点是完全有效可行的。避免节点加入到错误集群，要规定好集群名。

## node

节点是单个服务，也是集群的组成部分。用于保存数据，参与集群的索引和查询功能。启动后默认有一个uuid名。可以被修改。

当节点启动，并且他们之间可以彼此发现，将会自动组成并加入到elasticsearch集群。

对于一个集群，你可以加入你想要多的节点啊。开启一个节点，将会默认组成一个单节点集群且命名为elasticsearch。

## index、type

类型数据库的 库、表

在集群中，你可以定义你想要多的索引

在索引中，你可以一或多个类型。

## document

使用json格式，可以在index/type中存储你想要多的文档。

即使文档在物理上存储在索引上，但你必须将它编入到索引的类型上。

## shards&replicas

如果一个索引存放大量的数据，占用了1tb磁盘容量。对于一个节点上的索引来说，是难以负担的，而且会导致查询请求响应慢。

为了解决该文件，将索引拆分为多个分片。每个分片都是功能齐全且对立的索引。当创建索引的时候就可以去定义分片的数量，后续不能更改。分片会被托管到集群的任意节点上。

分片的两个重要原因：

- 允许水平扩展数据。
- 如果分片托管在多个节点上，那么它允许分布式并行地操作分片来提高性能和吞吐量。

在随时可能发生故障的网络/云环境，es提供了索引分片的复制，称为：副本分片或副本。

副本的两个重要原因：

- 提供高可用，副本分片不会被分配到和它的主分片同一个节点上。
- 由于可以在副本分片执行查询因此可以提高查询的吞吐量。

总结：每个索引会有多个分片，每个分片会有0-n个副本分片。主分片在索引创建后就固定了，而副本分片可以动态变更。

默认每个索引有5个主分片和一个副本（每个主分片都有一个副本分片）。且由于主分片和副本分片必须处于不同的节点上。所以如果只有一个节点，那么它的副本分片不会生成。如果有两个节点，那么就会有10个分片，5个主分片和5个副本分片。

## document num

Each Elasticsearch shard is a Lucene index. There is a maximum number of documents you can have in a single Lucene index. As of [`LUCENE-5843`](https://issues.apache.org/jira/browse/LUCENE-5843), the limit is `2,147,483,519` (= Integer.MAX_VALUE - 128) documents. You can monitor shard sizes using the `_cat/shards`

每个分片可以有20多亿个文档。

# exploring your cluster

## cluster health

`GET  /_cat/health?v`集群状态

status：

- 绿，集群完全健康
- 黄，主分片都健康，有副本分片未被分配（无可用于分配的节点）
- 红，部分分片不可用，但依旧可以查询，但是会缺少数据。

`GET /_cat/nodes?v`节点状态

## list all indices

`GET /_cat/indices?v`

## create an index

`PUT /customer?pretty`

pretty：为了让返回结果用漂亮的json格式打印

`GET /_cat/indices?v`

## index and query a document

```json
PUT /customer/external/1?pretty
{
	"name":"xxx xx"
}
```

录入文档，需要指定type。同时即使没有创建索引，如果索引不存在，以上操作也会自动创建customer索引，并在type为external下录入文档。

`GET /customer/externam/1?pretty`

## delete an index

`DELETE /customer`

综合以上的所有语句，可以看出es的语法结构如下：

`<REST Verb> /<Index>/<Type>/<ID>`

# modifying your data（against id）

```json
PUT /customer/external/1?pretty
{
	"name":"xxx xx"
}
```

以上操作多执行几次，都会覆盖id为1的数据。

如果不指定id，则会为这个文档生成一个随机id。同时如果没有指定id，那么用post而不用put

```json
POST /customer/external?pretty
{
  "name": "Jane Doe"
}
```

## updating documents

es并没有所谓的更新，其本质都是先删除后索引新的文档。

```json
POST /customer/external/1/_update?pretty
{
  "doc": { "name": "Jane Doe" }
}

POST /customer/external/1/_update?pretty
{
  "doc": { "name": "Jane Doe", "age": 20 }
}

POST /customer/external/1/_update?pretty
{
  "script" : "ctx._source.age += 5"
}
```

在5.5中，`_update`只用于一个文档的更新，在以后才可能会支持更新多文档，像sql中的（update where）

## deleing documents

`DELETE /customer/external/2?pretty`

[`_delete_by_query` API](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/docs-delete-by-query.html)  可以用于删除匹配到的文档。

值得一提的是，直接删除整个索引比使用delete by query api 来删除所有文档更有效。

## batch processing

```json
POST /customer/external/_bulk?pretty
{"index":{"_id":"1"}}
{"name": "John Doe" }
{"index":{"_id":"2"}}
{"name": "Jane Doe" }
{"update":{"_id":"1"}}
{"doc": { "name": "John Doe becomes Jane Doe" } }
{"delete":{"_id":"2"}}
```

批量操作提供了执行多种操作的机制，用于尽可能快且尽可能少的网络回返。

批量操作并不会因为某个操作失败而终止，它会继续执行下去。在返回的结果中，它提供了每个操作的状态，由此可以检查某个操作是否执行成功。

# exploring your data

导入数据，数据源：https://raw.githubusercontent.com/elastic/elasticsearch/master/docs/src/test/resources/accounts.json#

```json
curl -H "Content-Type: application/json" -XPOST 'localhost:9200/bank/account/_bulk?pretty&refresh' --data-binary "@accounts.json"
curl 'localhost:9200/_cat/indices?v'
```

## the search api

分为request uri 和request body。

```json
GET /bank/_search?q=*&sort=account_number:asc&pretty

GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}
```

必须知道的（不懂）：es一旦返回结果，将不再维护任何与服务段有关的资源或者在结果中打开游标。这和其他平台（sql）截然不同。

## introduce the query language

```json
GET /bank/_search
{
  "query": { "match_all": {} },
  "from": 10,
  "size": 10,
  "sort": { "balance": { "order": "desc" } }

}
```

针对bank索引，查询所有文档，并按照balance字段降序，然后返回第11到第20个文档。

## executing searches

## executing filters

## executing aggregations

