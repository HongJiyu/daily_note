document api ：针对指定文档的api

# reading and writing documents

本节主要介绍es的复制模型，并讨论在写和读的各种交互的操作时，它有怎样的影响。

## basic write model

略

# index api

在指定的索引下增加或者更新json格式的文档。

```json
PUT twitter/tweet/1
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}
```

```json
{
    "_shards" : {
        "total" : 2,
        "failed" : 0,
        "successful" : 1
    },
    "_index" : "twitter",
    "_type" : "tweet",
    "_id" : "1",
    "_version" : 1,
    "created" : true,
    "result" : created
}
```

total：录入该文档，涉及到的分片数量（包括主分片和副本分片）。

successful：成功录入的分片数量。

failed：失败的分片数量。

**注意：**如果只开启一个节点，且只有一个节点，并且索引配置如下：

```json
{
    "settings" : {
        "index" : {
            "number_of_shards" : 3, 
            "number_of_replicas" : 4
        }
    }
}
//录入一个文档后，返回如下：
{
    "_shards" : {
        "total" : 5,
        "failed" : 0,
        "successful" : 1
    }
}
```

已知只有一个节点，所以该节点都是主分片，所有的副本分片都没有启动。

total：是基于number_of_replicas，因此是4+1（4个副本+1个主分片）

failed：没有失败，主分片成功了，而没有副本分片，因此不算入失败。

successful：只有主分片并且成功。

## automatic index creation

如果之前没有创建索引，那么以上操作会自动创建索引。

如果之前没有创建映射，那么以上操作会自动创建映射，同时映射是非常灵活无结构的。会根据新的字段或者对象自动创建映射。

禁止自动创建：在所有的节点的配置文件中加上：

`action.auto_create_index`

`index.mapper.dynamic`

同时索引创建支持黑/白名单。

`action.auto_create_index`： `+aaa*,-bbb*,+ccc*,-*`

## versioning

## version types

## operation type

`PUT twitter/tweet/1` 默认是覆盖。

可以通过参数`op_type`，只有在不存在时才创建，存在时失败。

```json
PUT twitter/tweet/1?op_type=create
PUT twitter/tweet/1/_create
```

## automatic id generation

如果没有指定id，id会自动生成。

```json
POST twitter/tweet/
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}
```

## routing

```json
POST twitter/tweet?routing=kimchy
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}
```

默认一个文档的录入，会根据id来计算hash值，然后再确定会被放入到指定的分片上。如果指定`routing`，那么会根据这个`routing`值来替换id值计算来存放。

routing也可以在映射中指定。

作用：如果一个查询

```json
GET /testindex/_doc/_search
{
    "query":{
        "match":{
            "content":"get a dog"
        }
    }
}
```

该查询会将请求广播到所有分片，然后各自查完再返回协调节点，整合后再返回给用户。

如果一开始在录入时就指定了这类文档的位置，

`POST /testindex/_doc?routing=xxxx`

那么在查询时这样指定：

`GET /testindex/_doc/_search?routing=xxxx`

那么就不需要广播到所有分片，而是直接在计算得到的指定分片下去查找。可以提高效率，减少性能开销。

缺点：文档分布不均匀。

## parents & children

```json
PUT blogs
{
  "mappings": {
    "tag_parent": {}, //父类型
    "blog_tag": {     // 子类型
      "_parent": {    //在子类型指定其父
        "type": "tag_parent"
      },
       "properties":{}
    }
  }
}

PUT blogs/blog_tag/1122?parent=1111
{
    "tag" : "something"
}
```

当录入子文档时，其routing值自动被设置为与其父一致。除非有明确指定了routing值。

## distributed

录入操作基于路由被直接对准主分片并且在拥有该主分片的节点上执行。等到主分片完成操作后，如果需要，他会更新到副本分片上。

## wait for active shards

为了系统写的弹性，可以配置一个参数。使得写操作只有指定数量的分片是活跃的，才会去执行。默认是主分片活跃即可。

在索引上配置：`index.write.wait_for_active_shards`。

在请求url上配：`wait_for_active_shards`

其值为all 或者 1<=x<number_of_replicas+1 。

会在执行写请求前，去判断当前索引的活跃分片是否达到数量了。如果没有，则会进行等待直到超时。

因为检查是在写操作之前。如果检查时活跃分片是符合，但是执行时有活跃分片有问题。那么也会导致写的分片数量与预期不符合。

## refresh

具体看refresh

## noop updates

当使用index api更新文档时（put 替换指定id的文档），即使文档没有改变内容，它的version值也会总是被更新。

如果是 update api，可以使用`detect_noop`值去设置。而index api不适用，因为index api不回去获取旧资源，因此也就不会比较文档是否变更了。



## timeout

当执行索引操作时，被分配执行索引操作的主分片可能不可用。例如：主分片正从网关恢复或者处理迁移状态。默认情况下，索引操作会等待主分片最多一分钟。这个值可以被设置：

```json
PUT twitter/tweet/1?timeout=5m
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}
```

# get api

通过文档id获取指定的文档。

`GET twitter/tweet/0`

可以通过head请求来判断文档是否存在

`HEAD twitter/tweet/0`

## realtime

get api 会就地触发refresh，因此即使文档更新了，但是没有refresh。在get api操作时，更新的文档也是可见的。可以使用`realtime=false`去禁止此操作。

## optional type

可以使用`_type`去指定搜索的index下的type。`_type=_all`会在所有的type中获取第一个匹配到id的文档。

## source filtering

get api 默认会返回source字段，除非指定了stored_fields参数或者 _source被禁用。

`_source=false` 不返回source，如果不需要文档内容，使用该参数可以减少网络开销。

`_source_include`：包含

`_source_exclude`：不包含

`_soucre`：包含或者是否要返回_source字段

用逗号分隔开列表，可以使用通配符表达式

```json

GET twitter/tweet/0?_source_include=*.id&_source_exclude=entities

GET twitter/tweet/0?_source=*.id,retweeted
```

## stored fields

指定返回`stored_fields`，那么不会返回`_source`，同时被指定的字段在mapping中必须是`store=true`，否则返回时会被忽略。

```json
PUT twitter
{
   "mappings": {
      "tweet": {
         "properties": {
            "counter": {
               "type": "integer",
               "store": false
            },
            "tags": {
               "type": "keyword",
               "store": true
            }
         }
      }
   }
}

PUT twitter/tweet/1
{
    "counter" : 1,
    "tags" : "red"
}

GET twitter/tweet/1?stored_fields=tags,counter

{
   "_index": "twitter",
   "_type": "tweet",
   "_id": "1",
   "_version": 1,
   "found": true,
   "fields": {
      "tags": [
         "red"
      ]
   }
}
```

`stored_field`字段返回的都是数组的形式，同时由于counter在mapping并没有被指定为`store=true`，因此返回结果没有它。

Also only leaf fields can be returned via the `field` option. So object fields can’t be returned and such requests will fail

不懂：`leaf fields` 具体是什么字段

## getting the _source directly

```json
//只返回source字段
GET twitter/tweet/1/_source
//只返回source字段的同时，指定只返回source中的指定字段。
GET twitter/tweet/1/_source?_source_include=*.id&_source_exclude=entities'
//判断source是否存在。
HEAD twitter/tweet/1/_source
```

source不存在的情况只有：在mapping中如下配置

```json
PUT tweets
{
  "mappings": {
    "tweet": {
      "_source": {
        "enabled": false
      }
    }
  }
}
```

## routing

如果index 文档时，使用了routing。那么get 文档时，同样需要指定routing。如果routing不一致，那么会导致搜索不到该文档。

## preference

get api默认从副本分片中随机查。可以修改这个机制。

- preference=_primary ：只从主分片查。
- preference=_local：如果可以的话（当前协调节点就存有数据u送在的分片），直接从当前节点进行查。
- custom (string) value ： 不懂。A custom value will be used to guarantee that the same shards will be used for the same custom value. This can help with "jumping values" when hitting different shards in different refresh states. A sample value can be something like the web session id, or the user name

## refresh

在get之前，刷新相关分片。使得所有文档可见。

## distributed

get操作会先根据routing/id计算hash值得到分片的id，然后会重定向到分片上去获取并返回结果。这个分片是这个分片id组中的其中一个。因此如果分片有更多的副本，那么将会有更好的扩展性。

## versioning support

# delete api



# refresh

index、update、delete和bulk api 支持使用refresh去控制什么时候可见到该请求所作出的修改。

- refresh/ refresh=true：操作发生后，立即刷新相关的分片（主和副本）。因此更新后的文档可以立即在查询结果中。使用该值必须慎重考虑是否会导致低性能。
- refresh=wait_for：会等待该请求做出的修改 因 刷新变得可见 才会响应该请求。它并不会立即刷新，而是等待刷新发生。es自动刷新分片`index.refresh_interval`默认是1秒。或者手动调用[refresh](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-refresh.html)，或者在index、update、delete和bulk api使用refresh参数。都会导致刷新。进而导致refresh=wait_for的请求被响应。
- refresh=false/不使用该参数：不刷新。

## example

```json
//刷新
PUT /test/test/1?refresh
{"test": "test"}
PUT /test/test/2?refresh=true
{"test": "test"}

//不刷新
PUT /test/test/3
{"test": "test"}
PUT /test/test/4?refresh=false
{"test": "test"}

//等待刷新后再响应
PUT /test/test/4?refresh=wait_for
{"test": "test"}
```

## refresh=wait_for can force a refresh

如果当前分片上已经有`index.max_refresh_listeners`（默认1000）个请求在等待，那么再有一个refresh=wait_for请求进来，那么这个请求会被设置为refresh=true 进而触发刷新。同时这个请求的响应会包含`"forced_refresh": true`

每个bulk 请求只会对每个分片都只占用一个槽，不管他们对分片修改多少次。

## choosing which setting to use

- 如果对一个索引有很多改变，则使用wait_for比true更节省工作。
- true会创建低效的索引结构，后续会被合并到高效的索引结构。意味着true的开销在：创建低效索引结构的开销，在这个低效的索引结构查询的开销，合并到高效索引结构的开销。
- 不连续地使用refresh=wait_for的请求。而是将他们放入到balk请求中（使用refresh=wait_for）。es将会并行处理他们，并在他们全部完成后返回。
- 如果将`index.refresh_interval`设置为-1，则不会自动刷新，那么wait_for的请求只能等待手动调用[refresh](https://www.elastic.co/guide/en/elasticsearch/reference/5.5/indices-refresh.html)，或者在index、update、delete和bulk api使用refresh参数。刷新后才会响应。如果将`index.refresh_interval`设置过短，那么wait_for请求会很快响应。
- refresh=wait_for 只会影响它自己的请求，而true会影响其他正在进行的请求。因此如果你不希望打扰到系统上的其他请求，那么选择wait_for会较小的修改。