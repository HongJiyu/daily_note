# 计算机资源

pod对资源的请求量和陷质量是它所包含的所有容器的请求量和限制量之和。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: requests-pod
spec:
  containers:
  - image: busybox
  	command: ["dd","if=/dev/zero","of=/dev/null"]
  	name: main
  	resources:
  	  requests:
  	    cpu: 200m
  	    memory: 10Mi
```

容器内存10MB，cpu为200毫核（注意1000毫核写作1），即cpu运行1s，有5分之一的时间用于该容器运行。**这是最低要求，而不是限制最大值。**

当没有指定cpu时间时，最坏的情况时根本分不到cpu时间。着对于处理用户请求的容器很不合适。

指定最小需求后，调度器会根据需求量去寻找能够提供资源的节点。（调度只关注资源的requests，并不关注实际使用量）

![image-20201025110057817](img\image-20201025110057817.png)

通过以下命令查看界定啊资源的两组信息：总量和可分配量。**如果无够资源的节点，那么节点会一直处于pending**

```shell
kubectl describe nodes 
```

只有等节点资源释放后，这个pending的pod才会被调度。

## CPU Request

两个pod分别request  200和1000 毫核。

- 两个pod都全力跑满cpu，那么未使用的cpu也会按照1：5分配给这两个pod。
- 如果一个处于空闲，那么另一个可以使用整个cpu时间。
- 如果一个从空闲又开始跑，那么另一个从使用整个cpu时间变成被限制成1：5

![image-20201025144634745](img\image-20201025144634745.png)

## 限制容器的可用资源

cpu是可压缩资源，我们不需要对容器内运行的进程产生不利影响的同时，对其使用量进行限制。而内存不同，它是不可压缩资源，如果为某进程分配了内存。它在进程主动释放钱，无法被回收。

因为前面的申请资源是最低限制。满足即可被调度到符合的节点。但是pod可以使用超出最低限制的资源。如果使用内存，超出了。那么实际内存变小。会导致新进入的pod申请的最低限度比实际可用的要少。

### 带limits的pod

```yaml
apiVersion :v1
kind: Pod
metadata:
  name: limited-pod
spec:
  containers:
  - image: busybox
    command: ["dd","if=/dev/zero","of=dev/null"]
    name: main
    resources:
      limits:
        cpu: 1
        memory: 20Mi
```

​	这个pod容器包含了cpu和内存资源limits配置。没有指定requests，它将被设置与资源limits相同的值。

  **limits总和允许超过节点资源的总量，即limits可以超卖。如果节点资源使用量超过100%，一些容器将被杀掉**

![image-20201025150503281](img\image-20201025150503281.png)

### 超过limit

cpu是可压缩资源，即使实际需要超过limit，也只会被分配limit的值。

内存是不可压缩资源，如果实际需要超过limit，会直接oom。也就是被杀掉，同时重启策略是always或OnFailure，进程会立即重启。status为：CrashLoopBackOff，如果一直重启，它等待时间会边长，10、20、40、80、直到300秒，那么下次重启就会是等待300秒再重启。

![image-20201025151959681](img\image-20201025151959681.png)

OOMKilled 告诉我们容器因为内存不足而被系统杀掉。

**在容器内部用top看到的始终是节点的内存，而不是容器本身的内存**

其他：

![image-20201025154853369](img\image-20201025154853369.png)

![image-20201025153706649](img\image-20201025153706649.png)

## pod QoS等级

如果两个pod，pod A使用了90%内存，这时候podB需要比之前更多的内存，这时节点无法供应。那么哪个容器应该被杀掉？

pod被划分为3中QoS等级：

- BestEffort 最低

- Burstable

- Guaranteed  最高

BestEffort：pod中所有的容器都没有设置request和limits。

Guaranteed：pod中所有的容器都设置了request和limits，而且两者值一致（只设置limits也是，因为会默认没设置的request和limits同值）

Burstable：其他的pod都属于这类。

BestEffort 的pod最先被杀死，其次是Burstable，而Guaranteed只有在系统进程需要内存时才会被杀掉。

### 处理相同等级的容器

系统会杀掉内存实际使用量占内存申请量比例更高的pod：

![image-20201025161049587](img\image-20201025161049587.png)

## 为命名空间中的pod设置默认的requests和limits

创建LimitRange来避免为每个容器配置requests和limits。

![image-20201025162100676](img\image-20201025162100676.png)

LimitRange资源被LimitRanger准入控制插件。该插件对pod spec进行校验，校验失败，直接拒绝。如果没有它，api服务器接收pod请求，但是永远无法调度成功。

**LimitRange适用于该命名空间下的所有新创建的pod**

### LimitRange对象

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: example
spec:
  limits:
  - type: Pod
    min:
      cpu: 50m
      memory: 5Mi
    max:
      cpu: 1
      memory: 1Gi
  - type: Container
    defaultRequest:
      cpu: 100m
      memory: 100Mi
    default:
      cpu: 100m
      memory: 100Mi
    min:
      cpu: 50m
      memory: 5Mi
    max:
      cpu: 1
      memory: 1Gi
    maxLimitRequestRatio:
      cpu: 4
      memory: 10
  - type: PersistentVolumeClaim
    min:
      storage: 1Gi
    max:
      storage: 10G1
```

![image-20201025163140352](img\image-20201025163140352.png)

同样的，如果修改了限制，对于已存在的pod和pvc将不会进行校验改变，只会限制新建立的pod和pvc。

LimitRange只限制单独的pod，用户可以创建大量的pod吃掉集群中所有可用资源，LimitRange并不能防止这个，因此需要使用ResourceQuota可以做到。

## 限制命名空间的可用资源总量

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: cpu-and-mem
spec:
  hard:
    requests.cpu: 400m
    requests.memory: 200Mi
    limits.cpu: 600m
    limits.memory: 500Mi
```

```shell
kubectl describe quota
```

![image-20201025164236020](img\image-20201025164236020.png)

当创建了ResourceQuota时必须创建一个LimitRange，否则api服务器不会接收该pod的创建请求。

## 为持久化存储指定配额

![image-20201025205330843](img\image-20201025205330843.png)

## 限制可创建对象的个数

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: objects
spec:
  hard:
    pods: 10
    xxx:xx
```

![image-20201025205306044](img\image-20201025205306044.png)

## 为特定pod状态或Qos等级指定配额

BestEffort :QoS等级是BestEffort的pod

NotBestEffort：QoS等级是Burstable、Guaranteed的pod

Termination：配置了activeDeadlineSeconds的pod

NotTerminating：没有配置activeDeadlineSeconds的pod

activeDeadlineSeconds：pod被指定标记为Failed后，真正停止之前还可以运行的时间。

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: objects
spec:
  scopes:
  - BestEffort
  - NotTerminating
  hard:
    pods: 10
```

这个命名空间下最多创建4个属于BestEffort Qos等级且没有设置activeDeadlineSeconds的pod。

如果针对的是NotBestEffort 的pod，还可以指定cpu和memory。

## 监控pod的资源使用量

kubelet自身包含一个名为cAdvisor的agent，它负责收集所在节点上运行的所有容器的资源消耗情况。

同时需要一个Heapster的附加组件来统计所有cAdvisor的数据。

![image-20201025210802663](img\image-20201025210802663.png)

### 启用Heapster

Minikube 中，它作为插件使用

https://github.com/kubenetes/heapster

```shell
minikube addons enable heapster
```

### 显示集群节点的CPU和内存使用量

显示节点上运行的所有pod当前cpu和内存的实际使用量。

```shell
kubectl top node
```

查看集群下所有pod的情况。

```shell
kubectl top pod --all-namespaces
```

### 保存并分析历史资源的使用统计信息

cAdvisor和Heapster都只保存一个很短时间窗的资源使用量数据。如果要分析一段时间的pod资源使用情况，必须使用额外工具：InfluxDB统计数据、Grafana可视化和分析。

如果是Google Container Engine可以通过Goole Cloud Monitoring监控。

具体：439