# 应用滚动升级

场景：将应用从v1升级到v2版本。

方案：

1. 更改ReplicationController，然后把pod全部删除掉，ReplicationController会创建出新的pod。（为啥不能记录下所有pod，然后挨个删除）

2. 多创建一个ReplicationController，等所有的pod启动后，直接切换service的标签选择器。
3. 执行滚动升级操作。同样是使用两个ReplicationController。

第三种的具体操作：

灵活使用标签选择器。

原先： rc1 : k1=v1   svc: k1=v1

修改标签选择器 :   rc1 : k1=v1,k2=v1	svc: k1=v1

新增rc： rc2: k1=v1 , k3=v3

这时候service管理着 rc1和rc2创建的pod，但是rc1和rc2分别管理着自己的pod。

这时候 将 rc1 减少一个， rc2 多增一个。 逐步升级就可以了。

## ReplicationController实现自动滚动升级

1. 准备好v1版本的应用。
2. 修改镜像为v2版本。
3. 执行shell命令。

```shell
kubectl rolling-update kubia-v1 <newRCName> --image=<newImgName>
```

**注意：一定要看：**

镜像拉取策略：imagePullPolicy：always/ifNotPresent。

![image-20201018221644482](E:\0git_note\docker\img\image-20201018221644482.png)

它的执行流程类似第三种，具体去看page：261

### 过时的原因

1. 修改了原有的pod和ReplicationController的标签。
2. kubectl只是执行滚动升级过程中所有这些步骤的客户端。

```shell
kubectl rolling-update kubia-v1 <newRCName> --image=<newImgName> --v 6 #提高日志级别，使得所有的kubectl发起的到API服务的请求都会被输出
```

可以看到一个PUT请求：

/api/v1/namespaces/default/replicationcontrollerrollers/kubia-v1

它表示请求减少kubia-v1的副本数量

可以看出pod的伸缩请求是由kubectl客户端执行官的，而不是服务端执行的。

因此如果出现网络中断，那么滚动升级将会处于中间状态。

3. k8s应该做到的是期望副本数量伸缩pod而不是通过客户端手动删除pod或增加pod，因该是在pod定义中修改期望的tag，k8s用运行新镜像的pod替换旧的pod。而ReplicationController和ReplicaSet则只有replica变了，才会去做变化，image变了，不会改变已有的pod。

## Deployment声明式地升级应用

Deployment是更高级的资源，创建一个Deployment，ReplicaSet资源也会随之创建。在使用Deployment时，实际是由Deployment和Replicaset创建和管理的。

![image-20201018224223349](E:\0git_note\docker\img\image-20201018224223349.png)

使用Deployment更容易更新应用程序，因为可以直接定义当个Deployment资源所需达到的状态，并让k8s处理中间状态。