# 应用滚动升级

场景：将应用从v1升级到v2版本。

方案：

1. 更改ReplicationController，然后把pod全部删除掉，ReplicationController会创建出新的pod。（为啥不能记录下所有pod，然后挨个删除）

2. 多创建一个ReplicationController，等所有的pod启动后，直接切换service的标签选择器。
3. 执行滚动升级操作。同样是使用两个ReplicationController。

第三种的具体操作：

灵活使用标签选择器。

原先： rc1 : k1=v1   svc: k1=v1

修改标签选择器 :   rc1 : k1=v1,k2=v1	svc: k1=v1

新增rc： rc2: k1=v1 , k3=v3

这时候service管理着 rc1和rc2创建的pod，但是rc1和rc2分别管理着自己的pod。

这时候 将 rc1 减少一个， rc2 多增一个。 逐步升级就可以了。

## ReplicationController实现自动滚动升级

1. 准备好v1版本的应用。
2. 修改镜像为v2版本。
3. 执行shell命令。

```shell
kubectl rolling-update kubia-v1 <newRCName> --image=<newImgName>
```

**注意：一定要看：**

镜像拉取策略：imagePullPolicy：always/ifNotPresent。

![image-20201018221644482](img\image-20201018221644482.png)

它的执行流程类似第三种，具体去看page：261

### 过时的原因

1. 修改了原有的pod和ReplicationController的标签。
2. kubectl只是执行滚动升级过程中所有这些步骤的客户端。（要保持终端连接）

```shell
kubectl rolling-update kubia-v1 <newRCName> --image=<newImgName> --v 6 #提高日志级别，使得所有的kubectl发起的到API服务的请求都会被输出
```

可以看到一个PUT请求：

/api/v1/namespaces/default/replicationcontrollerrollers/kubia-v1

它表示请求减少kubia-v1的副本数量

可以看出pod的伸缩请求是由kubectl客户端执行官的，而不是服务端执行的。

因此如果出现网络中断，那么滚动升级将会处于中间状态。

3. k8s应该做到的是期望副本数量伸缩pod而不是通过客户端手动删除pod或增加pod，因该是在pod定义中修改期望的tag，k8s用运行新镜像的pod替换旧的pod。而ReplicationController和ReplicaSet则只有replica变了，才会去做变化，image变了，不会改变已有的pod。

## Deployment声明式地升级应用

Deployment是更高级的资源，创建一个Deployment，ReplicaSet资源也会随之创建。在使用Deployment时，实际是由Deployment和Replicaset创建和管理的。

![image-20201018224223349](img\image-20201018224223349.png)

使用Deployment更容易更新应用程序，因为可以直接定义当个Deployment资源所需达到的状态，并让k8s处理中间状态。

```yaml
apiVersion: aap/v1beta1
kind: Deployment
metadata:
  name:kubia
spec:
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app:kubia
    spec: 
      containers:
      - image: luksa/kubia:v1
        name: nodejs
```

启动

```shell
kubectl create -f kubia-deployment-v1.yaml --record
```

--record。这个选项会记录历史版本号。

查看部署状态

```shell
kubectl rollout status deployment kubia
```

查看deployment创建的rs和pod

```shell
kubectl get po
kubctl get replicasets
```

可以看到命名都有统一的数字，这些数字是pod的哈希值。deployment会创建多个replicasets，每个replicaset对应一个版本。replicaset和pod的数字是一样的，则可以认为这些pod由这个replicaset管理。（其实还是标签选择器决定）

### Deployment作用

只需要修改pod模板即可，不需要像ReplicationController 执行语句。

升级策略：

RollingUpdate：滚动

Recreate：删除所有pod，再新增pod

## 升级演示

```shell
kubectl patch deployment kubia -p '{"spec":{"minReadySeconds":10}}'
```

patch 用于修改单个或少量资源非常有用。

更改Deployment自有属性、副本数、部署策略 ，都不会出发滚动升级，现有运行的pod不会受影响。

触发滚动升级：

```shell
kubectl set image deployment kubia nodejs=luksa/kubia:v2
```

![image-20201019224653193](img\image-20201019224653193.png)

整个升级过程由运行再k8s上的控制器处理和完成的，而不是由客户端执行了。

**注意：**如果引用一个ConfigMap或Secret，如果只应该ConfigMap是不会触发升级。想要触发升级，就应该新建一个，然后pod引用新的ConfigMap

```shell
kubectl get rs
```

可以看到旧的ReplicaSet没有被删除，它会被用于回滚，而且我们只需要关心Deployment，而不需要去注意ReplicaSet，它只是实现的细节。

## 回滚

手动 回滚

```shell
kubectl rollout undo deployment kubia
```

undo命名也可以在滚动升级过程中运行，会直接停止滚动升级，同时升级过程已创建的pod会被删除并被老版本的pod替代。

查看升级版本：

```shell
kubectl rollout history deployment kubia
```

![image-20201019230051747](img\image-20201019230051747.png)

指定回滚版本：

```shell
kubectl rollout undo deployment kubia --to-revision=1
```

之所以可以回滚：replicaSet不会被删除，它记录了版本历史，Deployment创建的所有ReplicaSet表示完整的修改版本历史，所以不应该手动删除ReplicaSet。这样会导致丢失历史版本记录而无法回滚。

![image-20201019230425444](img\image-20201019230425444.png)

旧版本过多，可以通过revisionHistoryLimit限制ReplicaSet的数量。默认值是2.

extensions/v1beta1版本的没有值，而aps/v1beta2默认为10

## 控制滚动升级速率

```yaml
spec:
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
```

maxSurge: 可以是百分数或数值，表示deployment中的期望值外，pod在升级过程能超出多少个，默认是25% ，也可以是数字。（1表示超出1个，总共由4个；25%表示，超出1个）

maxUnavailable：最大多少个不可用，数值或百分比。

## 暂停滚动升级

```shell
kubectl rollout pause depployment kubia
```

恢复：

```shell
kubectl rollout resume deployment kubia
```

无法在一个确切的位置暂停。

暂停也可以用来组织更新Deployment而触发的滚动升级，进行多次修改后，再恢复滚动升级。

## 阻止出错的版本的滚动升级

minReadySeconds：可以控制 pod 处于就绪状态的观察时间。如果 pod 中的容器在这段时间内都能正常运行，k8s 才会认为新 pod 可用。在pod可用之前，不会继续进行滚动升级。如果一个新的pod运行出错，并且在minReadySeconds时间内它的就绪探针出现了失败，那么新版本的滚动升级将被阻止。

```yaml
apiVersion: aap/v1beta1
kind: Deployment
metadata:
  name:kubia
spec:
  replicas: 3
  miniReadySeconds: 10
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      name: kubia
      labels:
        app:kubia
    spec: 
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        readinessProbe:
          periodSeconds: 1
          httpGet:
            path: /
            port: 8080
```

```shell
kubectl get po
```

可以看到多了一个pod，但是未就绪。

过程应该是：进程启动，在minReadySeconds时间内，就绪探针一直访问（而不是一次成功就停止了），如果探测出现了错误，就无法就绪。升级暂停。

**不懂：minReadySeconds和就绪探针之间的关系。**

就绪探针：一直探测，一直失败，在请求成功后，不是应该就表明这个容器就绪，不再进行探测了吗。和上面的过程完全不一样了。

### 设置deadline

默认情况，10分钟无法完成滚动升级，将被视为失败。可以通过progressDeadlineSeconds来指定。

**注意：extensions/v1beta1版本不会设置默认的deadline**

因滚动升级不再继续，通过`rollout undo`取消滚动升级。

**注意：在后续版本，如果达到了指定的时间，则滚动升级自动取消**