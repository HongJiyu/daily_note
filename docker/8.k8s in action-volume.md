# volume

pod中每个容器都有自己独立的文件系统，因为文件系统来自容器镜像。有时候希望数据能够被保存，或者pod间的容器能够进行共享数据，k8s通过定义存储卷满足这个需求。

**volume是pod的一部分**，pod中的所有容器都可以使用卷，前提是必须将**它挂载在每个需要访问它的容器中**。

使用卷可以做到pod中的容器共享数据。

## emptyDir

**用于存储临时数据，且一开始是一个空目录。卷的生存周期和pod的生存周期相关联，删除pod时，卷的内容也会丢失。**

数据不会持久化，随着pod删除，数据丢失。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: fortune
spec:
  containers:
    - image: luksa/fortune
      name: html-generator
      volumeMounts:
      - name: html
        mountPath: /var/htdocs
    - image: nginx:alpine
      name: web-server
      volumeMounts: #挂载某个卷
      - name: html #挂载html卷
        mountPath: /usr/share/nginx/html #容器的这个路径
        readOnly: true
      ports:
      - containerPort: 80
        protocol: TCP
volume: #卷在这里定义
- name: html #命名
  emptyDir: {} #卷的类型
```

html-generator用于每10秒修改一个index.html文件。

web-server是nginx镜像，用于显示html页面内容。

命名为html的卷是一个空目录，它承载pod的工作节点的实际磁盘。同时容器html-generator和容器web-server都挂载在这个html卷上，共享同一份资源。

### 指定emptydir的介质

它是在承载pod的工作节点上的实际磁盘上创建的，因此卷的性能取决于磁盘类型，我们可以指定存储在内存。

```yaml
volumes:
  - name: html
    emptyDir:
      medium: Memory #指定存储在内存
```

## gitRepo（略）

它基本也是一个emptyDir卷，它是通过克隆Git仓库并在pod启动时检出特定版本来填充数据。pod被删除，它也会被删除

**注意：**使用gitRepo时，它会拉取网站的最新版本并开始托管网站，但是如果之后有更新，它pod不会去拉取最新的。而必须删除pod，创建的新的pod才会去托管最新的数据。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gitrepo-volume-pod
spec:
  containers:
  - image: nginx:alpine
    name: web-server
    volumeMounts: #挂载某个卷
    - name: html #挂载html卷
      mountPath: /usr/share/nginx/html #容器的这个路径
      readOnly: true
    ports:
    - containerPort: 80
      protocol: TCP
volume: #卷在这里定义
- name: html #命名
  gitRepo:  #卷的类型
    repository: https://github.com/HongJiyu/kubia-website-example.git
    revision: master
    directory: .
```

不使用directory为句号，则容器内目录：/usr/share/nginx/html/kubia-website-example

使用directory为句号，则容器内目录：

![image-20201017225848864](img\image-20201017225848864.png)

这三个文件，其中就能找到index.html ，而不会说多了一层kubia-website-example文件夹。

### sidecar容器

可以多开一个容器，用于保持gitrepo和git内容同步。略。。page:170

### 总结

gitRepo和emptyDir 一样，用于包含卷的容器使用。当pod被删除，卷和内容被删除。但是也有其他类型的卷并不创建新目录，而是将现有的外部目录挂载到pod容器文件系统中。

## hostPath

持久性卷，某些pod需要读取节点的文件或者使用节点文件系统来访问节点设备。

它的数据会存储在**集群节点**上，并且不会随着pod的删除而删除，同时新的pod入股使用了相同的路径的hostpath卷，那么新pod会发现上一个pod留下的数据，**注意：前提是必须是在同一个节点上。**

例子：

使用minikube，试试查看在kube-system命名空间下的storage-provisioner这个pod

```shell
kubectl get ns
kubectl get pod -n kube-system
kubectl describe pod storage-provisioner --namespace kube-system
```

## 不同基础设置的持久化卷

### gcePersistemDisk（略）

集群节点部署在google compute engine（gce）上，则可以使用此持久化卷

k8s集群运行在不同的引擎下，应根据不同的基础设施使用其他类型的卷。具体看page：173. 

minikube无法使用此类型。

1. 先创建持久磁盘
2. 编写yaml文件

```yaml
apiVersion: v1
kind: pod
metadata:
  name: mongodb
spec:
  volumes:
  - name: mongodb-data
    gcePersistentDisk: #持久卷类型
      pdName: mongodb # 使用在第一步创建的持久磁盘的命名
      fsType: ext4 # linux文件系统类型
  containers:
  - image: mongo
    name: mongodb
    volumeMounts:
    - name: mongodb-data
      mountPath: /data/db
    ports:
    - containerPort: 27017
      protocol: TCP
```

### 解耦（持久卷和持久化声明）

通过创建 持久化卷、持久化卷声明来解耦。

前部是全部有开发人员去根据底层基础设施创建持久化磁盘，然后编写yaml文件去指定。

现在通过持久化卷和持久化卷声明，由集群管理人员设置底层存储，然后创建持久化卷。而由研发人员则创建持久化卷声明，然后在pod指定持久化卷声明即可。

![image-20201018094352131](img\image-20201018094352131.png)

**注意：**持久卷卷不属于任何命名空间，它是集群层面的资源。

![image-20201018100428522](img\image-20201018100428522.png)

#### 管理员

1. 创建持久磁盘
2. 编写持久卷。

```yaml
apiVsersion: v1
kind: PersistentVolume
metadata:
  name: mongodb-pv
spec:
  capacity:
    storage: 1Gi #卷的大小
  accessModes: #访问模式
  - ReadWriteOnce # 单个客户端挂载为读写模式
  - ReadOnlyMany # 多个客户端挂载为只读
  persistentVolumeReclaimPolicy: Retain #声明释放后，仍然保留
  gcePersistentDisk: # 根据持久磁盘来编写下面内容
    pdName: mongodb
    fsType: ext4
```

```shell
kubectl create -f <name>
kubectl get pv
```



#### 研发人员

1. 持久化卷声明

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
spec:
  resources:
    requests:
      storage:1Gi
  accessModes:
  - ReadWriteOnce
  storageClassName: "" #暂时不用理会
```

```shell
kubectl create -f <name>
kubectl get pvc
kubectl get pv #声明匹配上了，那么pv状态也会变
```



可以看到声明只是强调想要的持久化磁盘的信息，不涉及底层基础设施内容。

1. 在pod中挂载声明

```yaml
apiVersion: v1
kind: pod
metadata:
  name: mongodb
spec:
  volumes:
  - name: mongodb-data
    persistentVolumeClaim: #持久卷声明
      claimName: mongodb-pvc #声明的名称
  containers:
  - image: mongo
    name: mongodb
    volumeMounts:
    - name: mongodb-data
      mountPath: /data/db
    ports:
    - containerPort: 27017
      protocol: TCP
```



可以看出研发人员只需要声明自己想要的磁盘容量和访问方式，然后k8s会自动去匹配适宜的持久化卷，即可。研发人员不需要去关心底层基础设施，因为分工了，这部分交由集群管理人员去操作。

#### 回收持久卷

```shell
kubectl delete pod mongodb
kubectl delete pvc mongodb-pvc
# 上面删除了pod和持久化声明，然后重新建立持久化声明，查看声明和卷的状态。
kubectl get pvc # pending 
kubectl get pv #released，而不是available
```

因为这个卷可能包含前一个声明人的数据，如果管理员没有清除，就不应该将这个卷绑定在声明中。

可以设置卷 persistentVolumeReclaimPolicy为Retain。让k8s可以在持久化卷从声明中释放后，然后保留它的数据。

Recycle：卷从声明释放后，删除卷内容，然后该卷可以被继续使用（gce无法使用）

Delete：删除底层存储和卷

## 持久卷的动态卷配置

管理人员配置StorageClass，研发人员声明中指定StorageCLass而不是持久卷，持久卷由StorageClass创建。

略。。page：187